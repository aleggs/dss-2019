{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datascience import *\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "import warnings\n",
    "warnings.simplefilter('ignore', FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_table = pd.read_json(\"Sarcasm_Headlines_Dataset_v2.json\", lines = True)\n",
    "articles = Table.from_df(pandas_table)\n",
    "headlines = articles.column('headline')\n",
    "headlines_train = headlines[:int(0.7*len(headlines))]\n",
    "labels_train = articles.column('is_sarcastic')[:int(0.7*len(headlines))]\n",
    "headlines_test = headlines[int(0.7*len(headlines)):]\n",
    "labels_test = articles.column('is_sarcastic')[int(0.7*len(headlines)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = stopwords.words(\"english\")\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "def clean(textList):\n",
    "    def split_punctuations(word_list):\n",
    "        punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "        new_word_list = []\n",
    "        for word in word_list:\n",
    "            if word[0] in punctuations:\n",
    "                new_word_list.append(word[0])\n",
    "                word = word[1:]\n",
    "            if word != '':\n",
    "                if word[-1] in punctuations:\n",
    "                    punc = word[-1]\n",
    "                    word = word[:-1]\n",
    "                    if word != '':\n",
    "                        new_word_list.append(word)   \n",
    "                    new_word_list.append(punc)\n",
    "                else:\n",
    "                    new_word_list.append(word)\n",
    "        return new_word_list\n",
    "    cleaned_textlists = [[stemmer.stem(word) for word in text.split() if word.lower() not in sw] for text in textList]\n",
    "    cleaned_headlines = [' '.join(split_punctuations(textlist)) for textlist in cleaned_textlists]\n",
    "    return cleaned_headlines   \n",
    "\n",
    "def vectorize_fitter(textList):\n",
    "    cleanTextList = clean(textList)\n",
    "    vectorizer = CountVectorizer()\n",
    "    vectorizer.fit(cleanTextList)\n",
    "    return vectorizer\n",
    "\n",
    "def vectorize_text(vectorizer, textList):\n",
    "    return vectorizer.transform(clean(textList)).toarray()\n",
    "\n",
    "vectorizer = vectorize_fitter(headlines)\n",
    "features_train = vectorize_text(vectorizer, headlines_train)\n",
    "features_test = vectorize_text(vectorizer, headlines_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "clf.fit(features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6912415560214302\n"
     ]
    }
   ],
   "source": [
    "predictions = clf.predict(features_test)\n",
    "print(accuracy_score(labels_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 ... 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_counts = [len(headline) for headline in headlines]\n",
    "def augmented_predict(clf, features):\n",
    "    predictions = []\n",
    "    for i in range(len(features)):\n",
    "        \"\"\"\n",
    "        if character_counts[i] <= 10:\n",
    "            predictions.append(1)\n",
    "        elif sum(features[i]) <= 1 or sum(features[i]) >= 30:\n",
    "            predictions.append(1)\n",
    "        \"\"\"\n",
    "        word_list = get_words(features[i])\n",
    "        counter = False\n",
    "        if word_list:\n",
    "            for word in word_list:\n",
    "                if word in su:\n",
    "                    counter = True\n",
    "        if counter:\n",
    "            predictions.append(1)\n",
    "        else:\n",
    "            predictions.append(clf.predict([features[i]])[0])\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = vectorizer.get_feature_names()\n",
    "for word in words:\n",
    "    if len(word) == 1:\n",
    "        print(word)\n",
    "word_dict = vectorizer.vocabulary_\n",
    "def vectorize_string(sentence, vectorizer):\n",
    "    return vectorizer.transform(clean([sentence])).toarray()[0]\n",
    "def predict_headline(headline, vectorizer, clf):\n",
    "    return clf.predict(vectorizer.transform(clean([headline])).toarray())\n",
    "str_vec = vectorize_string(\"cat cat cat\", vectorizer)\n",
    "def get_words(str_vec):\n",
    "    word_list = []\n",
    "    for i in range(len(str_vec)):\n",
    "        if str_vec[i]:\n",
    "            print(words[i])\n",
    "            word_list.append(words[i])\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = articles.with_column('word_count', [len(headline.split()) for headline in headlines])\n",
    "articles = articles.with_column('character_count', [len(headline) for headline in headlines])\n",
    "word_counts = articles.column('word_count')\n",
    "character_counts = articles.column('character_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features_train = [[feature.copy()] for feature in features_train]\n",
    "new_features_test = [[feature.copy()] for feature in features_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(new_features_train)):\n",
    "    new_features_train[i].pop()\n",
    "    new_features_train[i] += [word_counts[i], character_counts[i]]\n",
    "for i in range(len(new_features_test)):\n",
    "    new_features_test[i].pop()\n",
    "    new_features_test[i] += [word_counts[22000+i], character_counts[22000+i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = GaussianNB()\n",
    "clf2.fit(new_features_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5744070101223749\n"
     ]
    }
   ],
   "source": [
    "predictions = clf2.predict(new_features_test)\n",
    "print(accuracy_score(labels_test, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
